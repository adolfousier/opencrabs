# OpenCrabs Configuration File
# Copy this file to one of these locations:
#   - Linux/macOS: ~/.opencrabs/config.toml
#   - Windows: %APPDATA%\opencrabs\config.toml or opencrabs\config.toml
#
# IMPORTANT: API keys should NOT be stored here!
# Instead, store API keys in keys.toml (chmod 600) for security:
#   - ~/.opencrabs/keys.toml
# Keys in keys.toml take priority over this file.

[database]
# Database file location (stores conversation history)
path = "~/.opencrabs/opencrabs.db"

[providers]
# ========================================
# OpenAI-Compat
ible Provider (Local LLMs)
# ========================================
# Use this for LM Studio, Ollama, LocalAI, etc.
[providers.custom]
enabled = true
base_url = "http://localhost:1234/v1/chat/completions"  # LM Studio default
models = ["kimi-k2.5", "glm-5", "MiniMax-M2.5", "qwen3-coder", "gpt-oss-120b", "llama-4-70B", "mistral-Large-3", "qwen3-coder-next"]

# â­ IMPORTANT: Set this to match the model name loaded in LM Studio!
# Common examples:
#   - qwen2.5-coder-7b-instruct
#   - codellama-7b-instruct
#   - deepseek-coder-6.7b-instruct
#   - llama-3.2-1b-instruct
default_model = "qwen2.5-coder-7b-instruct"

# Other local LLM servers:
# Ollama: base_url = "http://localhost:11434/v1/chat/completions"
# LocalAI: base_url = "http://localhost:8080/v1/chat/completions"

# ========================================
# Official OpenAI Provider
# ========================================
[providers.openai]
enabled = false
default_model = "gpt-4o"  # Optional: override default model

# ========================================
# Anthropic Provider (Claude)
# ========================================
[providers.anthropic]
enabled = false
default_model = "claude-sonnet-4-6"  # Optional: override default

# ========================================
# OpenRouter Provider (100+ models via OpenAI-compatible API)
# ========================================
[providers.openrouter]
enabled = false
base_url = "https://openrouter.ai/api/v1/chat/completions"
default_model = "qwen/qwen3-coder-next"  # Many options at openrouter.ai/models

# ========================================
# Minimax Provider (Chinese AI, OpenAI-compatible)
# ========================================
# Note: Minimax does NOT have a /models endpoint, so add models manually
[providers.minimax]
enabled = false
base_url = "https://api.minimax.io/v1"
default_model = "MiniMax-M2.5"
models = ["MiniMax-M2.5", "MiniMax-M2.1", "MiniMax-Text-01"]

# ========================================
# STT (Speech-to-Text) Providers
# ========================================
# Groq Whisper for transcription
[providers.stt.groq]
enabled = false
default_model = "whisper-large-v3-turbo"

# ========================================
# TTS (Text-to-Speech) Providers
# ========================================
# OpenAI TTS for voice output
[providers.tts.openai]
enabled = false
default_model = "gpt-4o-mini-tts"

# ========================================
# Agent Behaviour
# ========================================
[agent]
approval_policy = "ask"       # "ask" | "auto-session" | "auto-always"
max_concurrent = 4            # Maximum concurrent tool calls
context_limit = 200000         # Max context tokens

# ========================================
# Voice (STT / TTS)
# ========================================
[voice]
stt_enabled = true            # Enable speech-to-text
tts_enabled = false           # Enable text-to-speech
tts_voice = "ash"             # TTS voice name
tts_model = "gpt-4o-mini-tts" # TTS model

# ========================================
# Tips for Using Local LLMs
# ========================================
# 1. Make sure LM Studio is running before starting OpenCrabs
# 2. Load a model in LM Studio first
# 3. Set default_model to EXACTLY match the model name shown in LM Studio
# 4. Increase context length in LM Studio if you get overflow errors:
#    - Recommended: 8192 or higher
#    - Location: LM Studio > Model Settings > Context Length

# ==================================================
# Channels (Telegram / WhatsApp / Slack / Discord)
# ==================================================

[channels.whatsapp]
enabled = false
allowed_list = ["user19802389679", "user2890797897"]
channel_id = ["channel1890779", "channel289792323"]

[channels.discord]
enabled = false
allowed_list = ["user19802389679", "user2890797897"]
channel_id = ["channel1890779", "channel289792323"]

[channels.telegram]
enabled = false
allowed_list = ["user19802389679", "user2890797897"]
channel_id = ["channel1890779", "channel289792323"]

[channels.slack]
enabled = false
allowed_list = ["user19802389679", "user2890797897"]
channel_id = ["channel1890779", "channel289792323"]

# ==================================================
# Web Search (Brave, EXA, etc)
# ==================================================
