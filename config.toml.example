# OpenCrabs Configuration File
# Copy this file to one of these locations:
#   - Linux/macOS: ~/.opencrabs/config.toml
#   - Windows: %APPDATA%\opencrabs\config.toml or opencrabs\config.toml
#
# IMPORTANT: API keys should NOT be stored here!
# Instead, store API keys in keys.toml (chmod 600) for security:
#   - ~/.opencrabs/keys.toml
# Keys in keys.toml take priority over this file.

[database]
# Database file location (stores conversation history)
path = "~/.opencrabs/opencrabs.db"

[providers]
# ========================================
# Custom: OpenAI-Compatible Providers (Local LLMs, remote APIs)
# ========================================
# Define as many named custom providers as you need.
# First one with enabled = true is used.

[providers.custom.lm_studio]
enabled = true
base_url = "http://localhost:1234/v1/chat/completions"
models = ["kimi-k2.5", "glm-5", "MiniMax-M2.5", "qwen3-coder", "gpt-oss-120b", "llama-4-70B", "mistral-Large-3", "qwen3-coder-next"]
default_model = "qwen2.5-coder-7b-instruct"

[providers.custom.ollama]
enabled = false
base_url = "http://localhost:11434/v1/chat/completions"
models = ["mistral", "llama3", "codellama"]
default_model = "mistral"

# ========================================
# Official OpenAI Provider
# ========================================
[providers.openai]
enabled = false
default_model = "gpt-4o"  # Optional: override default model

# ========================================
# Anthropic Provider (Claude)
# ========================================
[providers.anthropic]
enabled = false
default_model = "claude-sonnet-4-6"  # Optional: override default

# ========================================
# OpenRouter Provider (100+ models via OpenAI-compatible API)
# ========================================
[providers.openrouter]
enabled = false
base_url = "https://openrouter.ai/api/v1/chat/completions"
default_model = "qwen/qwen3-coder-next"  # Many options at openrouter.ai/models

# ========================================
# Minimax Provider (Chinese AI, OpenAI-compatible)
# ========================================
# Note: Minimax does NOT have a /models endpoint, so add models manually
[providers.minimax]
enabled = false
base_url = "https://api.minimax.io/v1"
default_model = "MiniMax-M2.5"
models = ["MiniMax-M2.5", "MiniMax-M2.1", "MiniMax-Text-01"]

# ========================================
# STT (Speech-to-Text) Providers
# ========================================
# Groq Whisper for transcription
[providers.stt.groq]
enabled = false
default_model = "whisper-large-v3-turbo"

# ========================================
# TTS (Text-to-Speech) Providers
# ========================================
# OpenAI TTS for voice output
[providers.tts.openai]
enabled = false
default_model = "gpt-4o-mini-tts"
voice = "ash"             # TTS voice name
model = "gpt-4o-mini-tts" # TTS model

# ========================================
# Tips for Using Local LLMs
# ========================================
# 1. Make sure LM Studio is running before starting OpenCrabs
# 2. Load a model in LM Studio first
# 3. Set default_model to EXACTLY match the model name shown in LM Studio
# 4. Increase context length in LM Studio if you get overflow errors:
#    - Recommended: 8192 or higher
#    - Location: LM Studio > Model Settings > Context Length

# ==================================================
# Channels (Telegram / WhatsApp / Slack / Discord)
# ==================================================

[channels.whatsapp]
enabled = false
allowed_phones = ["+15551234567"]

[channels.discord]
enabled = false
allowed_channels = ["channel_id"]   # Where the bot operates (empty = all channels)
allowed_users = [123456789012345]   # Who the bot replies to (empty = everyone)

[channels.telegram]
enabled = false
allowed_users = [123456789]         # Who the bot replies to (empty = everyone)

[channels.slack]
enabled = false
allowed_channels = ["C12345678"]    # Where the bot operates (empty = all channels)
allowed_ids = ["U12345678"]         # Who the bot replies to (empty = everyone)

# ========================================
# Web Search Providers
# ========================================

[providers.web_search.exa]
enabled = true
# API key goes in keys.toml: [providers.web_search.exa] api_key = "..."

[providers.web_search.brave]
enabled = false
# API key goes in keys.toml: [providers.web_search.brave] api_key = "..."
